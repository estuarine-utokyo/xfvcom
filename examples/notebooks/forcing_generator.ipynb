{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91986d83-957b-4f3a-8a70-8048f3577f2d",
   "metadata": {},
   "source": [
    "# Forcing data generator\n",
    "**Author: Jun Sasaki Coded on 2025-06-19  Updated on 2025-06-19**<br>\n",
    "- The input data datetime is supposed to be JST, while using UTC in the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0fc628-987e-49f2-92f1-9025330135f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    print(\"This cell is skipped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e3adcd-e53d-483e-9011-73669107a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%skip\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from xfvcom.io.sources.timeseries import TimeSeriesSource\n",
    "\n",
    "ts = TimeSeriesSource(\n",
    "    Path(\"../data/sample_sjis.tsv\"),\n",
    "    interp_method=\"linear\",\n",
    ")\n",
    "\n",
    "timeline = pd.date_range(\"2024-12-31 15:00\", periods=5, freq=\"6h\", tz=\"UTC\")\n",
    "print(timeline)\n",
    "print(ts.get_series(\"flux\", timeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5103423a-b700-4c07-a188-a43b391ecab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%skip\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from xfvcom.io.sources.timeseries import TimeSeriesSource\n",
    "\n",
    "# 任意の sample_sjis.tsv を使用\n",
    "src = TimeSeriesSource(Path(\"../data/sample_sjis.tsv\"))\n",
    "timeline = pd.date_range(\"2025-01-01\", periods=3, freq=\"6h\", tz=\"UTC\")\n",
    "out = src.get(\"flux\", timeline)\n",
    "print(out)          # 欠落分は NaN\n",
    "timeline = pd.to_datetime(\n",
    "    [\"2024-12-31 15:00\", \"2025-01-01 03:00\", \"2025-01-01 15:00\"],\n",
    "    utc=True,\n",
    ")\n",
    "out = src.get_series(\"flux\", timeline)\n",
    "print(out)   # → array([120.,  nan, 130.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce7fc94-9843-45d4-867e-9e9dbc8d521a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%skip\n",
    "from pathlib import Path\n",
    "from xfvcom.io.sources.utils import load_timeseries_table\n",
    "\n",
    "# TSV 読み込み（Shift-JIS）\n",
    "df_tsv = load_timeseries_table(Path(\"../data/sample_sjis.tsv\"))\n",
    "print(df_tsv.head(), df_tsv.attrs[\"encoding\"])  # => 'cp932'\n",
    "\n",
    "# 欠損値が NaN になっているか確認\n",
    "assert df_tsv.isna().any().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aad947-be58-49c9-92ce-c09f1afbce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%skip\n",
    "from pathlib import Path\n",
    "from xfvcom.io.met_nc_generator import MetNetCDFGenerator\n",
    "\n",
    "\n",
    "# --- グリッドのみでプロットターを作る ---------------\n",
    "dat = Path(\"~/Github/TB-FVCOM/goto2023/input/TokyoBay18_grd.dat\").expanduser()\n",
    "\n",
    "gen = MetNetCDFGenerator(\n",
    "    grid_nc   = Path(dat),\n",
    "    start     = \"2025-01-01T00:00:00Z\",\n",
    "    end       = \"2025-01-02T00:00:00Z\",\n",
    "    dt_seconds= 3600,\n",
    "    utm_zone  = 54,        # ★ 必須：UTM ゾーン\n",
    "    # northern = True,     # 南半球の場合のみ False に変更\n",
    "    uwind     = 2.0,       # 以降は定数値を自由に上書き\n",
    "    vwind     = 1.0,\n",
    ")\n",
    "nc_path = gen.write(Path('wnd.nc'))      # デフォルト: TokyoBay18_wnd.nc\n",
    "print(\"written to\", nc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb837a6-cbdc-4377-9ee2-daf9afe138f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "from xfvcom.io.met_nc_generator import MetNetCDFGenerator\n",
    "\n",
    "# Example grid.dat path\n",
    "dat = Path(\"~/Github/TB-FVCOM/goto2023/input/TokyoBay18_grd.dat\").expanduser()\n",
    "\n",
    "# Prepare short_wave time-series table (Asia/Tokyo timestamps)\n",
    "ts_path = Path(\"short_wave.csv\")\n",
    "ts_path.write_text(\n",
    "    \"time,short_wave\\n\"\n",
    "    \"2025-01-01T00:00:00+09:00,300\\n\"\n",
    "    \"2025-01-01T12:00:00+09:00,250\\n\"\n",
    "    \"2025-01-02T00:00:00+09:00,280\\n\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "gen = MetNetCDFGenerator(\n",
    "    grid_nc=dat,\n",
    "    start=\"2025-01-01T00:00:00Z\",\n",
    "    end=\"2025-01-02T00:00:00Z\",\n",
    "    start_tz=\"UTC\", # \"ASIA/TOKYO\", \"UTC\"\n",
    "    dt_seconds=3600,\n",
    "    utm_zone=54,\n",
    "    ts_specs=[f\"{ts_path}:short_wave\"],\n",
    "    data_tz=\"UTC\",\n",
    "    uwind=2.0,\n",
    "    vwind=1.0,\n",
    ")\n",
    "\n",
    "gen.write(Path(\"met.nc\"))\n",
    "ds_met = xr.open_dataset(\"met.nc\", decode_times=False)\n",
    "ds_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b73df7-1c5d-41ff-b9db-3120d9d09a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_met.vwind_speed.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde45a5a-4c53-433e-9b4f-ae20de78fa50",
   "metadata": {},
   "source": [
    "## River data generator\n",
    "**Note:** When you edit the following cell, restart the notebook.\n",
    "- Specify time zone `start_tz` and `data_tz`. All datetime is converted to UTC internally and the time zone in the netcdf is also UTC.\n",
    "- If you want to ignore time zone, specify `start_tz='UTC'` and `data_tz='UTC'`, which will not convert time zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7024537b-df14-4bee-98b4-d958a578d97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from xfvcom.io.river_nc_generator import RiverNetCDFGenerator\n",
    "\n",
    "# 1) Create sample flux data in a DataFrame and save it as a CSV file.\n",
    "df = pd.DataFrame({\n",
    "    \"time\": pd.date_range(\"2024-12-31 00:00\", periods=3, freq=\"24h\"),\n",
    "    \"flux\": [100, 105, 110],   # River discharge (m³/s)\n",
    "})\n",
    "df.to_csv(\"arakawa_flux.csv\", index=False)\n",
    "\n",
    "# 2) Create NetCDF using RiverNetCDFGenerator\n",
    "gen = RiverNetCDFGenerator(\n",
    "    nml_path    = Path(\"../configs/rivers_minimal.nml\"),\n",
    "    start       = \"2025-01-01T00:00\",\n",
    "    end         = \"2025-01-01T12:00\",\n",
    "    start_tz    = \"UTC\", # \"ASIA/TOKYO\", # \"ASIA/TOKYO\" \"UTC\"\n",
    "    dt_seconds  = 3600,\n",
    "    data_tz     = \"UTC\", # \"ASIA/TOKYO\", # \"ASIA/TOKYO\" \"UTC\"\n",
    "    ts_specs    = [\"Arakawa=arakawa_flux.csv:flux\"],  # Use flux column in arakawa_flux.csv file\n",
    "    const_specs = [\"Arakawa.salt=0.05\"],              # Use the constant salinity\n",
    ")\n",
    "\n",
    "nc_bytes = gen.render()\n",
    "Path(\"river.nc\").write_bytes(nc_bytes)\n",
    "ds_river = xr.open_dataset(\"river.nc\", decode_times=False)\n",
    "ds_river\n",
    "#ds_river.Times.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f035ace-1e1f-46f2-8f98-1158c0673f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
