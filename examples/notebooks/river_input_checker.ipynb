{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# River Input Data Checker\n",
    "**Author Jun Sasaki Coded on 2025-09-04 Updated on 2025-09-04**<br>\n",
    "**Purpose:** Check and visualize FVCOM river input files without requiring simulation output\n",
    "\n",
    "This notebook reads:\n",
    "- FVCOM grid file (.grd)\n",
    "- River namelist file (.nml)\n",
    "- River NetCDF file (.nc)\n",
    "\n",
    "And visualizes:\n",
    "- River node locations on mesh map\n",
    "- Time series of river discharge, temperature, and salinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.io.img_tiles import GoogleTiles\n",
    "\n",
    "# Import xfvcom modules\n",
    "from xfvcom.io.input_loader import FvcomInputLoader\n",
    "from xfvcom import FvcomPlotter, FvcomPlotConfig, FvcomPlotOptions\n",
    "from xfvcom import parse_river_namelist\n",
    "from xfvcom import make_node_marker_post\n",
    "from xfvcom.grid import FvcomGrid\n",
    "\n",
    "# For development - optional cell skipping\n",
    "from IPython.core.magic import register_cell_magic\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    print(\"This cell is skipped.\")\n",
    "\n",
    "# Create directory for output images\n",
    "png_dir = Path(\"PNG\")\n",
    "png_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Notebook initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Input File Paths\n",
    "Modify these paths to point to your input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base directory for your FVCOM project\n",
    "base_path = Path(\"~/Github/TB-FVCOM/goto2023\").expanduser()\n",
    "\n",
    "# Grid file (required)\n",
    "grid_file = \"TokyoBay18_grd.dat\"  # or .dat file\n",
    "grid_path = base_path / \"input\" / grid_file\n",
    "\n",
    "# River input files\n",
    "river_nc_file = \"TokyoBayfinal16_river.nc\"\n",
    "river_nml_file = \"RIVERS_NAMELIST16.nml\"\n",
    "river_nc_path = base_path / \"input/2020\" / river_nc_file\n",
    "river_nml_path = base_path / \"input/2020\" / river_nml_file\n",
    "\n",
    "# UTM zone for Tokyo Bay (required for geographic grids)\n",
    "utm_zone = 54\n",
    "\n",
    "# Check if files exist\n",
    "print(f\"Grid file exists: {grid_path.exists()}\")\n",
    "print(f\"River NC exists: {river_nc_path.exists()}\")\n",
    "print(f\"River NML exists: {river_nml_path.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Grid Data\n",
    "Load the FVCOM grid file to get mesh structure and node coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load grid using FvcomInputLoader\n",
    "loader = FvcomInputLoader(\n",
    "    grid_path=grid_path,\n",
    "    utm_zone=utm_zone,\n",
    "    add_dummy_time=False,  # We don't need dummy time for this\n",
    "    add_dummy_siglay=False  # We don't need dummy sigma layers\n",
    ")\n",
    "\n",
    "# Get the dataset and grid object\n",
    "grid_ds = loader.ds\n",
    "grid_obj = loader.grid\n",
    "\n",
    "print(f\"Grid loaded successfully\")\n",
    "print(f\"Number of nodes: {grid_obj.node}\")\n",
    "print(f\"Number of elements: {grid_obj.nele}\")\n",
    "print(f\"Coordinate range:\")\n",
    "print(f\"  Longitude: {grid_ds.lon.min().values:.3f} - {grid_ds.lon.max().values:.3f}\")\n",
    "print(f\"  Latitude: {grid_ds.lat.min().values:.3f} - {grid_ds.lat.max().values:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load River Configuration\n",
    "Parse the river namelist file to get river names and node locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse river namelist\n",
    "river_df = parse_river_namelist(river_nml_path, to_zero_based=True)\n",
    "\n",
    "print(f\"Number of rivers: {len(river_df)}\")\n",
    "print(\"\\nRiver configuration:\")\n",
    "print(river_df[['name', 'grid_location', 'file']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load River NetCDF Data\n",
    "Read the river forcing NetCDF file to get time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load river NetCDF file with decode_times=False to handle non-standard time units\n",
    "river_ds = xr.open_dataset(river_nc_path, decode_times=False)\n",
    "\n",
    "print(\"River NetCDF variables:\")\n",
    "for var in river_ds.data_vars:\n",
    "    print(f\"  {var}: {river_ds[var].sizes} - {river_ds[var].attrs.get('long_name', 'No description')}\")\n",
    "\n",
    "# Handle time manually for FVCOM format\n",
    "if 'time' in river_ds:\n",
    "    # FVCOM uses Itime (days) and Itime2 (milliseconds since midnight)\n",
    "    # Convert to datetime\n",
    "    if 'Itime' in river_ds and 'Itime2' in river_ds:\n",
    "        # Convert modified julian day to datetime\n",
    "        base_date = pd.Timestamp('1858-11-17')  # Modified Julian Day epoch\n",
    "        days = river_ds.Itime.values\n",
    "        milliseconds = river_ds.Itime2.values\n",
    "        \n",
    "        # Create datetime array\n",
    "        times = []\n",
    "        for day, ms in zip(days, milliseconds):\n",
    "            dt = base_date + pd.Timedelta(days=int(day)) + pd.Timedelta(milliseconds=int(ms))\n",
    "            times.append(dt)\n",
    "        \n",
    "        # Replace time coordinate with proper datetime\n",
    "        river_ds = river_ds.assign_coords(time=pd.DatetimeIndex(times))\n",
    "    elif 'time' in river_ds.coords:\n",
    "        # Try to parse time values if they exist\n",
    "        try:\n",
    "            # Attempt to convert time values\n",
    "            time_units = river_ds.time.attrs.get('units', '')\n",
    "            if 'days since' in time_units:\n",
    "                # Parse reference date from units\n",
    "                ref_date_str = time_units.split('days since')[1].strip()\n",
    "                ref_date = pd.Timestamp(ref_date_str)\n",
    "                times = [ref_date + pd.Timedelta(days=float(t)) for t in river_ds.time.values]\n",
    "                river_ds = river_ds.assign_coords(time=pd.DatetimeIndex(times))\n",
    "        except:\n",
    "            print(\"Warning: Could not decode time values\")\n",
    "    \n",
    "    # Get time range\n",
    "    if isinstance(river_ds.time.values[0], (pd.Timestamp, np.datetime64)):\n",
    "        time_start = pd.Timestamp(river_ds.time.values[0])\n",
    "        time_end = pd.Timestamp(river_ds.time.values[-1])\n",
    "        print(f\"\\nTime range: {time_start} to {time_end}\")\n",
    "        print(f\"Number of time steps: {len(river_ds.time)}\")\n",
    "    else:\n",
    "        print(f\"\\nNumber of time steps: {len(river_ds.time)}\")\n",
    "\n",
    "# Check if number of rivers matches\n",
    "n_rivers_nc = river_ds.sizes.get('river', river_ds.sizes.get('rivers', 0))\n",
    "print(f\"\\nNumber of rivers in NetCDF: {n_rivers_nc}\")\n",
    "if n_rivers_nc != len(river_df):\n",
    "    print(f\"WARNING: Number mismatch with namelist ({len(river_df)} rivers)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot River Nodes on Mesh Map\n",
    "Visualize where the rivers are located on the mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plotter for visualization\n",
    "cfg = FvcomPlotConfig()\n",
    "plotter = FvcomPlotter(grid_ds, cfg)\n",
    "\n",
    "# Option to show river names (set to False to show only numbers)\n",
    "show_river_names = True\n",
    "\n",
    "# Set map domain\n",
    "xlim=(float(grid_ds.lon.min()), float(grid_ds.lon.max()))\n",
    "ylim=(float(grid_ds.lat.min()), float(grid_ds.lat.max()))\n",
    "\n",
    "# Define marker and text styling\n",
    "mkw = {\"marker\": \"o\", \"color\": \"red\", \"markersize\": 3, \"zorder\": 4}\n",
    "tkw = {\"fontsize\": 8, \"color\": \"yellow\", \"ha\": \"center\", \"va\": \"bottom\",\n",
    "       \"zorder\": 5, \"clip_on\": True}\n",
    "\n",
    "# Convert 0-based indices to 1-based for make_node_marker_post\n",
    "# (river_df.grid_location is already 0-based from parse_river_namelist)\n",
    "river_nodes_1based = river_df.grid_location + 1\n",
    "\n",
    "# Create post-processing function using make_node_marker_post\n",
    "pp = make_node_marker_post(\n",
    "    river_nodes_1based,  # Pass 1-based indices\n",
    "    plotter,\n",
    "    marker_kwargs=mkw,\n",
    "    text_kwargs=tkw,\n",
    "    index_base=1,\n",
    ")\n",
    "\n",
    "# Add river names if enabled\n",
    "if show_river_names:\n",
    "    # Create a wrapper function that calls both the marker function and adds names\n",
    "    def pp_with_names(ax):\n",
    "        # First call the original post-processing function\n",
    "        pp(ax)\n",
    "        \n",
    "        # Then add river names next to the numbers\n",
    "        for idx, row in river_df.iterrows():\n",
    "            node_idx = row['grid_location']  # 0-based index\n",
    "            lon = plotter.ds.lon.values[node_idx]\n",
    "            lat = plotter.ds.lat.values[node_idx]\n",
    "            \n",
    "            # Add river name text (slightly offset from the number)\n",
    "            ax.text(lon, lat - 0.002, f\"{row['name']}\", \n",
    "                    fontsize=7, color='yellow', \n",
    "                    transform=ccrs.PlateCarree(), \n",
    "                    ha='left', va='top', zorder=5,\n",
    "                    bbox=dict(boxstyle='round,pad=0.2', facecolor='black', alpha=0))\n",
    "    \n",
    "    post_process_func = pp_with_names\n",
    "else:\n",
    "    post_process_func = pp\n",
    "\n",
    "# Plot options\n",
    "opts = FvcomPlotOptions(\n",
    "    figsize=(10, 12),\n",
    "    add_tiles=True,\n",
    "    tile_provider=GoogleTiles(style=\"satellite\"),\n",
    "    mesh_color=\"#ffffff\",\n",
    "    mesh_linewidth=0.3,\n",
    "    title=\"River Input Nodes on FVCOM Mesh\",\n",
    "    # Adjust these bounds for your domain\n",
    "    xlim=xlim,\n",
    "    ylim=ylim,\n",
    ")\n",
    "\n",
    "# Create the plot\n",
    "ax = plotter.plot_2d(da=None, post_process_func=post_process_func, opts=opts)\n",
    "\n",
    "# Save figure\n",
    "ax.figure.savefig(png_dir / \"river_nodes_map.png\", dpi=150, bbox_inches='tight')\n",
    "print(\"River nodes map saved to PNG/river_nodes_map.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Plot River Time Series\n",
    "Visualize discharge, temperature, and salinity for each river"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the dimension name for rivers\n",
    "river_dim = 'river' if 'river' in river_ds.sizes else 'rivers'\n",
    "\n",
    "# Create figure with subplots for time series\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "fig.suptitle('River Input Time Series', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Convert time to pandas datetime for better plotting\n",
    "time_pd = pd.to_datetime(river_ds.time.values)\n",
    "\n",
    "# Plot 1: River discharge\n",
    "ax = axes[0]\n",
    "if 'river_flux' in river_ds:\n",
    "    for i in range(min(n_rivers_nc, len(river_df))):\n",
    "        river_name = river_df.iloc[i]['name'] if i < len(river_df) else f\"River {i+1}\"\n",
    "        flux = river_ds.river_flux.isel({river_dim: i}).values\n",
    "        ax.plot(time_pd, flux, label=river_name, linewidth=1)\n",
    "    ax.set_ylabel('Discharge (m³/s)', fontsize=12)\n",
    "    ax.set_title('River Discharge', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(ncol=3, loc='upper right', fontsize=8)\n",
    "\n",
    "# Plot 2: River temperature\n",
    "ax = axes[1]\n",
    "if 'river_temp' in river_ds:\n",
    "    for i in range(min(n_rivers_nc, len(river_df))):\n",
    "        river_name = river_df.iloc[i]['name'] if i < len(river_df) else f\"River {i+1}\"\n",
    "        temp = river_ds.river_temp.isel({river_dim: i}).values\n",
    "        ax.plot(time_pd, temp, label=river_name, linewidth=1)\n",
    "    ax.set_ylabel('Temperature (°C)', fontsize=12)\n",
    "    ax.set_title('River Temperature', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(ncol=3, loc='upper right', fontsize=8)\n",
    "\n",
    "# Plot 3: River salinity\n",
    "ax = axes[2]\n",
    "if 'river_salt' in river_ds:\n",
    "    for i in range(min(n_rivers_nc, len(river_df))):\n",
    "        river_name = river_df.iloc[i]['name'] if i < len(river_df) else f\"River {i+1}\"\n",
    "        salt = river_ds.river_salt.isel({river_dim: i}).values\n",
    "        ax.plot(time_pd, salt, label=river_name, linewidth=1)\n",
    "    ax.set_ylabel('Salinity (PSU)', fontsize=12)\n",
    "    ax.set_title('River Salinity', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(ncol=3, loc='upper right', fontsize=8)\n",
    "\n",
    "# Format x-axis\n",
    "axes[-1].set_xlabel('Time', fontsize=12)\n",
    "axes[-1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Adjust layout and save\n",
    "plt.tight_layout()\n",
    "fig.savefig(png_dir / \"river_timeseries.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"River time series saved to PNG/river_timeseries.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Individual River Analysis\n",
    "Select and analyze individual rivers in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a river to analyze (change this index as needed)\n",
    "river_index = 0  # First river (0-based index)\n",
    "\n",
    "if river_index < len(river_df):\n",
    "    river_info = river_df.iloc[river_index]\n",
    "    print(f\"Analyzing River: {river_info['name']}\")\n",
    "    print(f\"Node location (0-based): {river_info['grid_location']}\")\n",
    "    print(f\"Input file: {river_info['file']}\")\n",
    "    \n",
    "    # Get node coordinates\n",
    "    node_idx = river_info['grid_location']\n",
    "    lon = grid_ds.lon.values[node_idx]\n",
    "    lat = grid_ds.lat.values[node_idx]\n",
    "    print(f\"Coordinates: ({lon:.4f}°E, {lat:.4f}°N)\")\n",
    "    \n",
    "    # Get time series data\n",
    "    if river_index < n_rivers_nc:\n",
    "        flux = river_ds.river_flux.isel({river_dim: river_index})\n",
    "        temp = river_ds.river_temp.isel({river_dim: river_index}) if 'river_temp' in river_ds else None\n",
    "        salt = river_ds.river_salt.isel({river_dim: river_index}) if 'river_salt' in river_ds else None\n",
    "        \n",
    "        # Statistics\n",
    "        print(f\"\\nDischarge Statistics:\")\n",
    "        print(f\"  Mean: {flux.mean().values:.2f} m³/s\")\n",
    "        print(f\"  Min: {flux.min().values:.2f} m³/s\")\n",
    "        print(f\"  Max: {flux.max().values:.2f} m³/s\")\n",
    "        print(f\"  Std: {flux.std().values:.2f} m³/s\")\n",
    "        \n",
    "        if temp is not None:\n",
    "            print(f\"\\nTemperature Statistics:\")\n",
    "            print(f\"  Mean: {temp.mean().values:.2f} °C\")\n",
    "            print(f\"  Min: {temp.min().values:.2f} °C\")\n",
    "            print(f\"  Max: {temp.max().values:.2f} °C\")\n",
    "        \n",
    "        if salt is not None:\n",
    "            print(f\"\\nSalinity Statistics:\")\n",
    "            print(f\"  Mean: {salt.mean().values:.3f} PSU\")\n",
    "            print(f\"  Min: {salt.min().values:.3f} PSU\")\n",
    "            print(f\"  Max: {salt.max().values:.3f} PSU\")\n",
    "        \n",
    "        # Create detailed plot for this river\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(12, 8), sharex=True)\n",
    "        fig.suptitle(f\"River: {river_info['name']}\", fontsize=14, fontweight='bold')\n",
    "        \n",
    "        time_pd = pd.to_datetime(river_ds.time.values)\n",
    "        \n",
    "        # Discharge\n",
    "        axes[0].plot(time_pd, flux.values, 'b-', linewidth=1.5)\n",
    "        axes[0].set_ylabel('Discharge (m³/s)')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        axes[0].axhline(y=flux.mean().values, color='r', linestyle='--', alpha=0.5, label='Mean')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        # Temperature\n",
    "        if temp is not None:\n",
    "            axes[1].plot(time_pd, temp.values, 'r-', linewidth=1.5)\n",
    "            axes[1].set_ylabel('Temperature (°C)')\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Salinity\n",
    "        if salt is not None:\n",
    "            axes[2].plot(time_pd, salt.values, 'g-', linewidth=1.5)\n",
    "            axes[2].set_ylabel('Salinity (PSU)')\n",
    "            axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[-1].set_xlabel('Time')\n",
    "        axes[-1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        fig.savefig(png_dir / f\"river_{river_index}_{river_info['name'].replace(' ', '_')}.png\", \n",
    "                   dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(f\"\\nDetailed plot saved to PNG/river_{river_index}_{river_info['name'].replace(' ', '_')}.png\")\n",
    "else:\n",
    "    print(f\"River index {river_index} is out of range (0-{len(river_df)-1})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Export\n",
    "Create a summary report of all river inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary DataFrame\n",
    "summary_data = []\n",
    "\n",
    "for i in range(min(n_rivers_nc, len(river_df))):\n",
    "    river_info = river_df.iloc[i]\n",
    "    node_idx = river_info['grid_location']\n",
    "    \n",
    "    # Get statistics from NetCDF\n",
    "    flux = river_ds.river_flux.isel({river_dim: i})\n",
    "    temp = river_ds.river_temp.isel({river_dim: i}) if 'river_temp' in river_ds else None\n",
    "    salt = river_ds.river_salt.isel({river_dim: i}) if 'river_salt' in river_ds else None\n",
    "    \n",
    "    summary_data.append({\n",
    "        'River Name': river_info['name'],\n",
    "        'Node Index': node_idx,\n",
    "        'Longitude': grid_ds.lon.values[node_idx],\n",
    "        'Latitude': grid_ds.lat.values[node_idx],\n",
    "        'Mean Discharge (m³/s)': flux.mean().values,\n",
    "        'Max Discharge (m³/s)': flux.max().values,\n",
    "        'Mean Temp (°C)': temp.mean().values if temp is not None else np.nan,\n",
    "        'Mean Salinity (PSU)': salt.mean().values if salt is not None else np.nan,\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Display summary\n",
    "print(\"River Input Summary:\")\n",
    "print(\"=\"*80)\n",
    "print(summary_df.to_string())\n",
    "\n",
    "# Export to CSV\n",
    "csv_path = png_dir / \"river_summary.csv\"\n",
    "summary_df.to_csv(csv_path, index=False)\n",
    "print(f\"\\nSummary exported to {csv_path}\")\n",
    "\n",
    "# Calculate totals\n",
    "total_discharge = summary_df['Mean Discharge (m³/s)'].sum()\n",
    "print(f\"\\nTotal mean discharge from all rivers: {total_discharge:.2f} m³/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "This notebook provides a comprehensive tool for checking FVCOM river input files without requiring simulation output. \n",
    "\n",
    "### Key Features:\n",
    "1. **Direct Input File Reading**: Reads grid, river namelist, and river NetCDF files directly\n",
    "2. **Spatial Visualization**: Shows river node locations on the mesh\n",
    "3. **Time Series Analysis**: Plots discharge, temperature, and salinity for all rivers\n",
    "4. **Individual River Analysis**: Detailed analysis of selected rivers\n",
    "5. **Summary Export**: Creates CSV summary of all river inputs\n",
    "\n",
    "### Customization:\n",
    "- Modify file paths in Section 1 to point to your input files\n",
    "- Adjust plot bounds and styling in Section 5\n",
    "- Change the river index in Section 7 to analyze different rivers\n",
    "- Add additional analysis as needed\n",
    "\n",
    "### Requirements:\n",
    "- xfvcom package with FvcomInputLoader support\n",
    "- Grid file in .grd or .dat format\n",
    "- River namelist file (.nml)\n",
    "- River NetCDF file with standard FVCOM river variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
