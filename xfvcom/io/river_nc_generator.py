from __future__ import annotations

import tempfile
from datetime import timezone
from io import BytesIO
from pathlib import Path
from typing import Dict, List

import netCDF4 as nc
import numpy as np
import pandas as pd
from numpy.typing import NDArray

from .base_generator import BaseGenerator
from .rivers_nml_parser import parse_rivers_nml
from .sources.base import ConstantSource, RiverTimeSeriesSource


class RiverNetCDFGenerator(BaseGenerator):
    """Generate NetCDF-4 river forcing file from NML and constant sources."""

    def __init__(
        self,
        nml_path: Path,
        start: str,
        end: str,
        dt_seconds: int,
        default_flux: float = 0.0,
        default_temp: float = 20.0,
        default_salt: float = 0.0,
    ) -> None:
        super().__init__(nml_path)
        self.start = pd.Timestamp(start, tz="UTC")
        self.end = pd.Timestamp(end, tz="UTC")
        self.dt = dt_seconds
        self.default_flux = default_flux
        self.default_temp = default_temp
        self.default_salt = default_salt

    # --------------------------------------------------------------- #
    # Abstract-method overrides                                      #
    # --------------------------------------------------------------- #
    # --------------------------- helpers ---------------------------- #
    @staticmethod
    def _to_mjd(times: pd.DatetimeIndex) -> NDArray[np.float64]:
        """Return Modified Julian Day as a NumPy array (float64)."""
        mjd0 = pd.Timestamp("1858-11-17T00:00:00Z")
        return ((times - mjd0) / pd.Timedelta("1D")).to_numpy("f8")

    @staticmethod
    def _times_char(times: pd.DatetimeIndex) -> np.ndarray:
        """Return Times char array (time, DateStrLen=26)."""
        strs = times.strftime("%Y-%m-%dT%H:%M:%S.000000")
        return np.asarray([list(s.ljust(26)) for s in strs], dtype="S1")

    def load(self) -> None:
        """Parse rivers.nml and build timeline."""
        self.rivers = parse_rivers_nml(self.source)
        self.timeline = pd.date_range(
            self.start, self.end, freq=f"{self.dt}s", inclusive="both", tz="UTC"
        )

    def validate(self) -> None:
        if not self.rivers:
            raise ValueError("No river entries found in NML.")

    # ------------------------------------------------------------------
    # Low-level NetCDF writer
    # ------------------------------------------------------------------
    def render(self) -> bytes:
        """
        Build a river-forcing NetCDF-4 file that matches the original
        MATLAB/FVCOM layout *byte-for-byte*, and return its binary content.
        """
        # ---- 1. Pre-compute helper arrays --------------------------------
        nr = len(self.rivers)
        nt = self.timeline.size

        # Modified Julian Day (float32) and its split parts
        time_mjd_f32: NDArray[np.float32] = self._to_mjd(self.timeline).astype("f4")
        itime_i32: NDArray[np.int32] = time_mjd_f32.astype("i4")
        itime2_i32: NDArray[np.int32] = (
            (time_mjd_f32 - itime_i32) * 86_400_000
        ).astype("i4")

        # char arrays
        times_char = self._times_char(self.timeline)  # (nt, 26) S1
        rname_char = np.asarray(  # (nr, 80) S1
            [list(name.ljust(80)) for name in self.rivers], dtype="S1"
        )

        # constant source arrays
        const = ConstantSource(self.default_flux, self.default_temp, self.default_salt)
        flux_f4 = np.tile(
            const.get_series("flux", self.timeline).astype("f4").reshape(nt, 1), (1, nr)
        )
        temp_f4 = np.tile(
            const.get_series("temp", self.timeline).astype("f4").reshape(nt, 1), (1, nr)
        )
        salt_f4 = np.tile(
            const.get_series("salt", self.timeline).astype("f4").reshape(nt, 1), (1, nr)
        )

        # ---- 2. Write with netCDF4 - low level ---------------------------
        with tempfile.NamedTemporaryFile(suffix=".nc", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        with nc.Dataset(tmp_path, "w", format="NETCDF4_CLASSIC") as ds:
            # (a) dimensions â€” order is significant
            ds.createDimension("namelen", 80)
            ds.createDimension("rivers", nr)
            ds.createDimension("time", None)
            ds.createDimension("DateStrLen", 26)

            # (b) global attributes
            ds.type = "FVCOM RIVER FORCING FILE"
            ds.title = "Constant river forcing (prototype)"
            ds.history = "generated by xfvcom"
            ds.info = "flux in m3/s, temp in degC, salinity in PSU"

            # (c) coordinate & helper variables  --------------------------
            v_rnames = ds.createVariable("river_names", "S1", ("rivers", "namelen"))
            v_rnames[:, :] = rname_char

            v_time = ds.createVariable("time", "f4", ("time",))
            v_time[:] = time_mjd_f32
            v_time.long_name = "time"
            v_time.units = "days since 1858-11-17 00:00:00"
            v_time.format = "modified julian day (MJD)"
            v_time.time_zone = "UTC"

            v_itime = ds.createVariable("Itime", "i4", ("time",))
            v_itime[:] = itime_i32
            v_itime.units = v_time.units
            v_itime.format = v_time.format
            v_itime.time_zone = "UTC"

            v_itime2 = ds.createVariable("Itime2", "i4", ("time",))
            v_itime2[:] = itime2_i32
            v_itime2.units = "msec since 00:00:00"
            v_itime2.time_zone = "UTC"

            v_times = ds.createVariable("Times", "S1", ("time", "DateStrLen"))
            v_times[:, :] = times_char
            v_times.time_zone = "UTC"

            # (d) data variables  ----------------------------------------
            def _make(name: str, data: NDArray, long: str, unit: str) -> None:
                var = ds.createVariable(name, "f4", ("time", "rivers"), fill_value=None)
                var[:, :] = data
                var.long_name = long
                var.units = unit

            _make("river_flux", flux_f4, "river runoff volume flux", "m^3s^-1")
            _make("river_temp", temp_f4, "river runoff temperature", "Celsius")
            _make("river_salt", salt_f4, "river runoff salinity", "PSU")

        # read back binary and delete temp file
        binary = tmp_path.read_bytes()
        tmp_path.unlink(missing_ok=True)
        return binary
